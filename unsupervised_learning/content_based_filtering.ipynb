{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b236f4",
   "metadata": {},
   "source": [
    "<h2>Content-Based Filtering Algorithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "318e1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820d1aa",
   "metadata": {},
   "source": [
    "<h4>Content-Based Filtering Algorithm with TensorFlow</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "445df0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_filtering(output_units):\n",
    "    \n",
    "    tf.random.set_seed(42)\n",
    "    num_user_features = 14\n",
    "    num_item_features = 17\n",
    "    \n",
    "    user_neural_network = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=124, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=output_units, activation=\"linear\")\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    item_neural_network = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Dense(units=10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=output_units, activation=\"linear\")\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "    vu = user_neural_network(input_user)\n",
    "    vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "    \n",
    "    input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "    vm = item_neural_network(input_item)\n",
    "    vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "    output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "    model = tf.keras.Model([input_user, input_item], output)\n",
    "\n",
    "    return model.summary()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d449f",
   "metadata": {},
   "source": [
    "<h4>Analyze Data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df5d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie id</th>\n",
       "      <th>num ratings</th>\n",
       "      <th>ave rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4993</td>\n",
       "      <td>198</td>\n",
       "      <td>4.106061</td>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring,...</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5952</td>\n",
       "      <td>188</td>\n",
       "      <td>4.021277</td>\n",
       "      <td>Lord of the Rings: The Two Towers, The</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7153</td>\n",
       "      <td>185</td>\n",
       "      <td>4.118919</td>\n",
       "      <td>Lord of the Rings: The Return of the King, The</td>\n",
       "      <td>Action|Adventure|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4306</td>\n",
       "      <td>170</td>\n",
       "      <td>3.867647</td>\n",
       "      <td>Shrek</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy|Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58559</td>\n",
       "      <td>149</td>\n",
       "      <td>4.238255</td>\n",
       "      <td>Dark Knight, The</td>\n",
       "      <td>Action|Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6539</td>\n",
       "      <td>149</td>\n",
       "      <td>3.778523</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "      <td>Action|Adventure|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79132</td>\n",
       "      <td>143</td>\n",
       "      <td>4.066434</td>\n",
       "      <td>Inception</td>\n",
       "      <td>Action|Crime|Drama|Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6377</td>\n",
       "      <td>141</td>\n",
       "      <td>3.960993</td>\n",
       "      <td>Finding Nemo</td>\n",
       "      <td>Adventure|Animation|Children|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4886</td>\n",
       "      <td>132</td>\n",
       "      <td>3.871212</td>\n",
       "      <td>Monsters, Inc.</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7361</td>\n",
       "      <td>131</td>\n",
       "      <td>4.160305</td>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>Drama|Romance|Sci-Fi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie id  num ratings  ave rating  \\\n",
       "0      4993          198    4.106061   \n",
       "1      5952          188    4.021277   \n",
       "2      7153          185    4.118919   \n",
       "3      4306          170    3.867647   \n",
       "4     58559          149    4.238255   \n",
       "5      6539          149    3.778523   \n",
       "6     79132          143    4.066434   \n",
       "7      6377          141    3.960993   \n",
       "8      4886          132    3.871212   \n",
       "9      7361          131    4.160305   \n",
       "\n",
       "                                               title  \\\n",
       "0  Lord of the Rings: The Fellowship of the Ring,...   \n",
       "1             Lord of the Rings: The Two Towers, The   \n",
       "2     Lord of the Rings: The Return of the King, The   \n",
       "3                                              Shrek   \n",
       "4                                   Dark Knight, The   \n",
       "5  Pirates of the Caribbean: The Curse of the Bla...   \n",
       "6                                          Inception   \n",
       "7                                       Finding Nemo   \n",
       "8                                     Monsters, Inc.   \n",
       "9              Eternal Sunshine of the Spotless Mind   \n",
       "\n",
       "                                              genres  \n",
       "0                                  Adventure|Fantasy  \n",
       "1                                  Adventure|Fantasy  \n",
       "2                     Action|Adventure|Drama|Fantasy  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy|Ro...  \n",
       "4                                 Action|Crime|Drama  \n",
       "5                    Action|Adventure|Comedy|Fantasy  \n",
       "6         Action|Crime|Drama|Mystery|Sci-Fi|Thriller  \n",
       "7                Adventure|Animation|Children|Comedy  \n",
       "8        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "9                               Drama|Romance|Sci-Fi  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_data = pd.read_csv(\"/home/sam/projects/machine-learning/data/content_based/content_top10_df.csv\")\n",
    "by_genre_data = pd.read_csv(\"/home/sam/projects/machine-learning/data/content_based/content_bygenre_df.csv\")\n",
    "top_10_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c17338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>num movies</th>\n",
       "      <th>ave rating/genre</th>\n",
       "      <th>ratings per genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action</td>\n",
       "      <td>321</td>\n",
       "      <td>3.37</td>\n",
       "      <td>10377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>234</td>\n",
       "      <td>3.42</td>\n",
       "      <td>8785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animation</td>\n",
       "      <td>76</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children</td>\n",
       "      <td>69</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>326</td>\n",
       "      <td>3.36</td>\n",
       "      <td>8911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crime</td>\n",
       "      <td>139</td>\n",
       "      <td>3.54</td>\n",
       "      <td>4671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>13</td>\n",
       "      <td>3.81</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drama</td>\n",
       "      <td>342</td>\n",
       "      <td>3.61</td>\n",
       "      <td>10201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>124</td>\n",
       "      <td>3.37</td>\n",
       "      <td>4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Horror</td>\n",
       "      <td>56</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>68</td>\n",
       "      <td>3.59</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Romance</td>\n",
       "      <td>151</td>\n",
       "      <td>3.39</td>\n",
       "      <td>4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>174</td>\n",
       "      <td>3.42</td>\n",
       "      <td>5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>245</td>\n",
       "      <td>3.44</td>\n",
       "      <td>7659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          genre  num movies  ave rating/genre  ratings per genre\n",
       "0        Action         321              3.37              10377\n",
       "1     Adventure         234              3.42               8785\n",
       "2     Animation          76              3.63               2588\n",
       "3      Children          69              3.44               2472\n",
       "4        Comedy         326              3.36               8911\n",
       "5         Crime         139              3.54               4671\n",
       "6   Documentary          13              3.81                280\n",
       "7         Drama         342              3.61              10201\n",
       "8       Fantasy         124              3.37               4468\n",
       "9        Horror          56              3.20               1345\n",
       "10      Mystery          68              3.59               2497\n",
       "11      Romance         151              3.39               4468\n",
       "12       Sci-Fi         174              3.42               5894\n",
       "13     Thriller         245              3.44               7659"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_genre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3265dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    item_train = np.genfromtxt('/home/sam/projects/machine-learning/data/content_based/content_item_train.csv', delimiter=',')\n",
    "    user_train = np.genfromtxt('/home/sam/projects/machine-learning/data/content_based/content_user_train.csv', delimiter=',')\n",
    "    y_train    = np.genfromtxt('/home/sam/projects/machine-learning/data/content_based/content_y_train.csv', delimiter=',')\n",
    "    \n",
    "    with open('/home/sam/projects/machine-learning/data/content_based/content_item_train_header.txt', newline='') as f:  \n",
    "        item_features = list(csv.reader(f))[0]\n",
    "        \n",
    "    with open('/home/sam/projects/machine-learning/data/content_based/content_user_train_header.txt', newline='') as f:\n",
    "        user_features = list(csv.reader(f))[0]\n",
    "        \n",
    "    item_vecs = np.genfromtxt('/home/sam/projects/machine-learning/data/content_based/content_item_vecs.csv', delimiter=',')\n",
    "\n",
    "    movie_dict = defaultdict(dict)\n",
    "    count = 0\n",
    "    \n",
    "    with open('/home/sam/projects/machine-learning/data/content_based/content_movie_list.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        \n",
    "        for line in reader:\n",
    "            if count == 0:\n",
    "                count += 1    \n",
    "            else:\n",
    "                count += 1\n",
    "                movie_id = int(line[0])\n",
    "                movie_dict[movie_id][\"title\"] = line[1]\n",
    "                movie_dict[movie_id][\"genres\"] = line[2]\n",
    "\n",
    "    #with open('/home/sam/projects/machine-learning/data/content_based/content_user_to_genre.pickle', 'rb') as f:\n",
    "        #user_to_genre = pickle.load(f)\n",
    "\n",
    "    return(item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e85d468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50884, 17)\n",
      "(50884, 17)\n",
      "(50884,)\n",
      "17\n",
      "17\n",
      "(847, 17)\n",
      "847\n"
     ]
    }
   ],
   "source": [
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict = load_data()\n",
    "print(item_train.shape)\n",
    "print(user_train.shape)\n",
    "print(y_train.shape)\n",
    "print(len(item_features))\n",
    "print(len(user_features))\n",
    "print(item_vecs.shape)\n",
    "print(len(movie_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf4b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.87400000e+03, 2.00300000e+03, 3.96183206e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [8.79800000e+03, 2.00400000e+03, 3.76136364e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [4.69700000e+04, 2.00600000e+03, 3.25000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.68250000e+05, 2.01700000e+03, 3.63333333e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.68250000e+05, 2.01700000e+03, 3.63333333e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.68252000e+05, 2.01700000e+03, 4.28000000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d563e",
   "metadata": {},
   "source": [
    "<h4>Feature Scaling with scikit-learn</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0184c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_item = sklearn.preprocessing.StandardScaler()\n",
    "scaler_item.fit(item_train)\n",
    "item_train = scaler_item.transform(item_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4de33c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_user = sklearn.preprocessing.StandardScaler()\n",
    "scaler_user.fit(user_train)\n",
    "user_train = scaler_user.transform(user_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4468ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_target = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler_target.fit(y_train.reshape(-1, 1))\n",
    "y_train = scaler_target.transform(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d517e6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50884, 17)\n",
      "(50884, 17)\n",
      "(50884, 1)\n"
     ]
    }
   ],
   "source": [
    "print(item_train.shape)\n",
    "print(user_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838582f0",
   "metadata": {},
   "source": [
    "<h4>Split data into train and test sets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a555580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_train, item_test = sklearn.model_selection.train_test_split(item_train, train_size=0.8, shuffle=True, random_state=1)\n",
    "user_train, user_test = sklearn.model_selection.train_test_split(user_train, train_size=0.8, shuffle=True, random_state=1)\n",
    "y_train, y_test = sklearn.model_selection.train_test_split(y_train, train_size=0.8, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9d76a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40707, 17)\n",
      "(10177, 17)\n",
      "(40707, 17)\n",
      "(10177, 17)\n",
      "(40707, 1)\n",
      "(10177, 1)\n"
     ]
    }
   ],
   "source": [
    "print(item_train.shape)\n",
    "print(item_test.shape)\n",
    "print(user_train.shape)\n",
    "print(user_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ca3dbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 14)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, 17)]                 0         []                            \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)   (None, 32)                   39708     ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)   (None, 32)                   642       ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_2 (TF  (None, 32)                   0         ['sequential_5[0][0]']        \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_3 (TF  (None, 32)                   0         ['sequential_6[0][0]']        \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                 (None, 1)                    0         ['tf.math.l2_normalize_2[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.math.l2_normalize_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40350 (157.62 KB)\n",
      "Trainable params: 40350 (157.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "summary = content_based_filtering(output_units=32)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7970f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_filtering(user_train, item_train, y_train, user_test, \n",
    "                            item_test, y_test, output_units, epochs=100, learning_rate=1e-2):\n",
    "    \n",
    "    tf.random.set_seed(42)\n",
    "    num_user_features = user_train.shape[1] - 3 \n",
    "    num_item_features = item_train.shape[1] - 1\n",
    "    u_s = 3  # start of columns to use in training, user\n",
    "    i_s = 1  # start of columns to use in training, items\n",
    "    user_neural_network = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=124, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=output_units, activation=\"linear\")\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    item_neural_network = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Dense(units=10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=output_units, activation=\"linear\")\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "    vu = user_neural_network(input_user)\n",
    "    vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "    \n",
    "    input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "    vm = item_neural_network(input_item)\n",
    "    vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "    output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "    model = tf.keras.Model([input_user, input_item], output)\n",
    "    cost_function = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=cost_function)\n",
    "    model.fit([[user_train[:, u_s:], item_train[:, i_s:]]], y_train, epochs=epochs)\n",
    "    model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750986f",
   "metadata": {},
   "source": [
    "<h4>Train and Evaluate the Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0f7ea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0313\n",
      "Epoch 2/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0283\n",
      "Epoch 3/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0273\n",
      "Epoch 4/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0268\n",
      "Epoch 5/30\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.0261\n",
      "Epoch 6/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0257\n",
      "Epoch 7/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0253\n",
      "Epoch 8/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0250\n",
      "Epoch 9/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0245\n",
      "Epoch 10/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0243\n",
      "Epoch 11/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0240\n",
      "Epoch 12/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0238\n",
      "Epoch 13/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0236\n",
      "Epoch 14/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0234\n",
      "Epoch 15/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0232\n",
      "Epoch 16/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0231\n",
      "Epoch 17/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0229\n",
      "Epoch 18/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0228\n",
      "Epoch 19/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0226\n",
      "Epoch 20/30\n",
      "1273/1273 [==============================] - 3s 2ms/step - loss: 0.0225\n",
      "Epoch 21/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0223\n",
      "Epoch 22/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0223\n",
      "Epoch 23/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0222\n",
      "Epoch 24/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0221\n",
      "Epoch 25/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0220\n",
      "Epoch 26/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0219\n",
      "Epoch 27/30\n",
      "1273/1273 [==============================] - 3s 2ms/step - loss: 0.0218\n",
      "Epoch 28/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0218\n",
      "Epoch 29/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0217\n",
      "Epoch 30/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0217\n",
      "319/319 [==============================] - 1s 1ms/step - loss: 0.0228\n"
     ]
    }
   ],
   "source": [
    "content_based_filtering(\n",
    "    user_train=user_train, \n",
    "    item_train=item_train,\n",
    "    y_train=y_train,\n",
    "    user_test=user_test, \n",
    "    item_test=item_test, \n",
    "    y_test=y_test, \n",
    "    output_units=32, \n",
    "    epochs=30, \n",
    "    learning_rate=1e-2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
